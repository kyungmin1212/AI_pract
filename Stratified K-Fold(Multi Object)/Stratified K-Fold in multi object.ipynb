{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "dataset_path = './data'\n",
    "annotations_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "with open(annotations_file_path,'r') as f:\n",
    "    dataset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   image_id   class_name  class_id  x_min  y_min      w      h\n",
      "0      batch_01_vt/0002.jpg  Plastic bag       8.0  109.0  150.7  161.9  159.8\n",
      "1      batch_01_vt/0002.jpg  Plastic bag       8.0  413.2  196.1   72.6   52.7\n",
      "2      batch_01_vt/0002.jpg      Plastic       6.0   42.5  196.7   68.3   86.5\n",
      "3      batch_01_vt/0002.jpg        Glass       5.0    0.1  279.7  117.3  183.0\n",
      "4      batch_01_vt/0002.jpg        Glass       5.0  110.3   77.5   80.0  293.4\n",
      "...                     ...          ...       ...    ...    ...    ...    ...\n",
      "26395     batch_03/0997.jpg        Paper       2.0    0.0   97.2   28.9   82.9\n",
      "26396     batch_03/0997.jpg        Paper       2.0    0.0  151.4   17.7   24.1\n",
      "26397     batch_03/0997.jpg        Paper       2.0    0.0  261.0  112.8  147.7\n",
      "26398     batch_03/0997.jpg        Paper       2.0    0.3  426.3   16.7   85.6\n",
      "26399     batch_03/1000.jpg        Metal       4.0  258.7  158.3  124.9  272.0\n",
      "\n",
      "[26400 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = {'image_id': [],\n",
    "           'class_name': [],\n",
    "           'class_id': [],\n",
    "           'x_min': [],\n",
    "           'y_min': [],\n",
    "           'w': [],\n",
    "           'h': []}\n",
    "df = pd.DataFrame(raw_data)\n",
    "\n",
    "classes = [\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "categories = dataset['categories']\n",
    "annotations = dataset['annotations']\n",
    "images = dataset['images']\n",
    "\n",
    "all_row=[]\n",
    "for annotation in annotations:\n",
    "    file_name = images[annotation['image_id']]['file_name']\n",
    "    row = [file_name , classes[annotation['category_id']],int(annotation['category_id']),\n",
    "          annotation['bbox'][0],annotation['bbox'][1],annotation['bbox'][2],annotation['bbox'][3]]\n",
    "    all_row.append(row)\n",
    "    # file 이름 ,클래스이름 , 클래스id , x_min,y_min,w,h\n",
    "\n",
    "df = pd.concat([df,pd.DataFrame(all_row,columns=df.columns)],ignore_index=True)\n",
    "print(df)\n",
    "df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "\n",
    "# CFG.n_folds , CFG.seed 로 호출해서 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Seed All\n",
    "\n",
    "    Args:\n",
    "        seed: seed number\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# 전체 annotation 개수만큼 df 행이 있음 , image_names는 중복되는 값들이 있음 , images_name과 category_id가 똑같은것도 여러개 있을수 있음(한 이미지에 똑같은 카테고리가 여러개 있을수 있으므로)\n",
    "def stratified_k_fold(df,category_ids,image_names,k,seed=None):# df : df , category_ids : df['class_id'], image_names : df['image_id']\n",
    "    labels_num = np.max(category_ids) + 1 # 11 (category_ids는 0부터 10까지 존재 -> 전체 개수는 11개)\n",
    "    class_counts_per_image_names = defaultdict(lambda:np.zeros(labels_num))\n",
    "    class_counts_total = defaultdict(int)\n",
    "    \n",
    "    for category_id,image_name in zip(category_ids,image_names):\n",
    "        class_counts_per_image_names[image_name][category_id] += 1 # 한 이미지의 class 분포를 알아보기 위함\n",
    "        class_counts_total[category_id] += 1 # 전체 class 분포를 알아보기 위함\n",
    "        \n",
    "    class_counts_per_fold = defaultdict(lambda:np.zeros(labels_num)) # fold 당 class 분포를 알기 위함 -> fold 별로 class를 고르게 분포하게 해야함\n",
    "    image_names_per_fold = defaultdict(set) # fold 별로 image name을 분류하기 위함\n",
    "    \n",
    "    def eval_class_counts_per_fold(class_counts_image,fold): # 한 이미지의 class 분포를 보고 어떤 fold에 들어가면 좋을지 구하기 위하여 각 라벨들의 표준편차의 평균을 구함\n",
    "        class_counts_per_fold[fold] += class_counts_image # fold 에 우선적으로 현재 이미지의 클래스 분포를 넣어보기\n",
    "        # {0:[0,0,0,0,0,..,0],1:[0,0,0,0,...,0],...,4:[0,0,0,...,0]}\n",
    "        std_per_class = [] # class 별로 표준편차를 구함\n",
    "        for class_number in range(labels_num):\n",
    "            # fold 별로 각 class 의 개수에서 전체 데이터에 대한 그 class의 개수를 나눠주고 그 값들의 표준편차를 구함\n",
    "            # class_std 는 전체 fold 에 대해서 한 class의 표준편차를 보는것(데이터 퍼진정도를 보는것)\n",
    "            class_std = np.std([class_counts_per_fold[i][class_number]/class_counts_total[class_number] for i in range(k)])\n",
    "            std_per_class.append(class_std)\n",
    "        # std_per_class는 class 별로 표준편차를 나타내줌\n",
    "        class_counts_per_fold[fold] -= class_counts_image # fold에 한번 넣어서 표준편차를 구해본것-> 다시 원상복구(모든 fold에 넣어보고 그중 fold별로 class 분포의 표준편차가 제일 작은 값인 fold 에 그 이미지를 넣을것임\n",
    "        \n",
    "        # 한 fold에 어떤 클래스가 몰리게 되면 fold에 대한 그 클래스에 대한 표준편차는 커질것 -> 모든 클래스에 대해 고르게 분포해야하므로 전체 클래스에 대한 표준편차들의 평균을 이용\n",
    "        return np.mean(std_per_class) # 평균([fold별 0클래스에 대한 표준편차,fold별 1클래스에 대한 표준편차,...,fold별 10클래스에 대한 표준편차])\n",
    "    \n",
    "    image_names_and_class_counts = list(class_counts_per_image_names.items()) # [('image_name',[0,0,0,0,...,0]),('image_name',[0,0,0...,0]),...]\n",
    "    random.Random(seed).shuffle(image_names_and_class_counts) # 리스트를 랜덤하게 섞어줌\n",
    "    \n",
    "    # 한 이미지의 class_counts의 표준편차가 큰거(한 클래스에 많은 값이 몰려있을수 있기 때문에 미리 처리)부터 fold 별 분류 시작\n",
    "    for image_name,class_counts in sorted(image_names_and_class_counts,key=lambda x:-np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k): # 한 개의 이미지를 k개의 fold에 다 넣어보고 그중 가장 fold별로 class 분포가 고르게 퍼지게 할수있는 fold에 그 이미지를 넣어줌\n",
    "            fold_eval = eval_class_counts_per_fold(class_counts,i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        class_counts_per_fold[best_fold] += class_counts # fold에 이제 삽입이 되었으므로 그 fold에 그 이미지에 해당하는 class 분포를 넣어줌\n",
    "        image_names_per_fold[best_fold].add(image_name) # image_name을 fold별로 기록\n",
    "    \n",
    "    all_image_names = set(image_names) # 중복되지 않는 이미지 이름들 , 즉 전체 이미지 개수만큼 있음\n",
    "    \n",
    "    for i in range(k):\n",
    "        train_image_names = all_image_names - image_names_per_fold[i]\n",
    "        test_image_names = image_names_per_fold[i]\n",
    "        \n",
    "        # image_names 는 전체 annotations 개수 , 중복되는 이미지이름 존재\n",
    "        # df 에서 image_name이 우리가 이미지별 클래스 분포에 따라 분류한 i번째 fold에 있다면 인덱스 번호를 저장 \n",
    "        train_indices = [i for i,image_name in enumerate(image_names) if image_name in train_image_names]\n",
    "        test_indices = [i for i,image_name in enumerate(image_names) if image_name in test_image_names]\n",
    "        # 즉 df 에서 이미지 이름이 같다면 다 같은 fold 일것임 (우리는 이미지에 따라 분류를 했기 때문)\n",
    "        \n",
    "        yield train_indices,test_indices # df의 index 번호들이 저장되어져있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(df, config):\n",
    "    df_folds = df[['image_id']].copy() ## df[['image_id']] 괄호가 2개이면 Dataframe 한개면 Series로 지정됨\n",
    "    df_folds.loc[:, 'bbox_count'] = 1\n",
    "    # 여기까지는 중복되는 이미지가 포함 , annotation 정보에 따라 만들어진 df\n",
    "    \n",
    "    # groupby count을 통해 중복되는 데이터가 몇개인지 표시 , groupby 했으므로 index가 image_id로 변경됨\n",
    "    df_folds = df_folds.groupby('image_id').count() # 이미지별로 객체가 몇개있는지 파악\n",
    "    # fold 번호 지정해주기 위한 열 생성\n",
    "    df_folds['fold'] = 0\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(\n",
    "            stratified_k_fold(df, df['class_id'], df['image_id'], config.n_folds, config.seed)):\n",
    "        \n",
    "        # df의 인덱스를 지정해주고 그 인덱스와 image_id를 지정해주면 그에 맞는 값들이 나오고 unique를 통해서 리스트 형태로 만들어주기\n",
    "        trn_ids = df.loc[trn_idx, 'image_id'].unique() # unique 한값을 ['batch_01_vt/0003.jpg' ,...,'batch_03/1000.jpg'] 처럼 리스트로 만들어줌\n",
    "        val_ids = df.loc[val_idx, 'image_id'].unique()\n",
    "        assert len(set(trn_ids).intersection(set(val_ids))) == 0 # 이 조건을 만족안하면 train하고 valid가 겹치는것이 있으므로 잘못된것!\n",
    "\n",
    "        df_folds.loc[val_ids, 'fold'] = fold # valid에 fold번호를 붙여줌\n",
    "    return df_folds # 이미지별 fold 정보가 저장된 df 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    meta_df = pd.read_csv(f\"./data.csv\")\n",
    "    meta_df = meta_df.reset_index(drop=True)\n",
    "\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = load_all_data()\n",
    "meta_df['class_id']=meta_df['class_id'].astype(int)\n",
    "\n",
    "seed_everything()\n",
    "f_folds = get_folds(meta_df,CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      bbox_count  fold\n",
      "image_id                              \n",
      "batch_01_vt/0002.jpg          17     0\n",
      "batch_01_vt/0003.jpg          14     3\n",
      "batch_01_vt/0005.jpg           1     4\n",
      "batch_01_vt/0006.jpg           2     4\n",
      "batch_01_vt/0007.jpg           2     1\n",
      "...                          ...   ...\n",
      "batch_03/0994.jpg              7     4\n",
      "batch_03/0995.jpg             14     0\n",
      "batch_03/0996.jpg              4     2\n",
      "batch_03/0997.jpg              8     2\n",
      "batch_03/1000.jpg              1     4\n",
      "\n",
      "[3272 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_folds = f_folds.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image_id  bbox_count  fold\n",
      "0     batch_01_vt/0002.jpg          17     0\n",
      "1     batch_01_vt/0003.jpg          14     3\n",
      "2     batch_01_vt/0005.jpg           1     4\n",
      "3     batch_01_vt/0006.jpg           2     4\n",
      "4     batch_01_vt/0007.jpg           2     1\n",
      "...                    ...         ...   ...\n",
      "3267     batch_03/0994.jpg           7     4\n",
      "3268     batch_03/0995.jpg          14     0\n",
      "3269     batch_03/0996.jpg           4     2\n",
      "3270     batch_03/0997.jpg           8     2\n",
      "3271     batch_03/1000.jpg           1     4\n",
      "\n",
      "[3272 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2617\n",
      "655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:13<00:54, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2611\n",
      "661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:27<00:40, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613\n",
      "659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:40<00:27, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625\n",
      "647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:54<00:13, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622\n",
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:08<00:00, 13.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 기존 형태를 가져오기 위해 json 파일 load\n",
    "dataset_path = './data'\n",
    "annotations_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "with open(annotations_file_path,'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "    \n",
    "\n",
    "# 똑같이 json 형태로 만들어주는 과정\n",
    "for idx in tqdm(range(5)):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    \n",
    "    # fold별 train,valid 이미지 name list로 만들기\n",
    "    train_file_names = f_folds[f_folds['fold']!=idx]['image_id'].unique() # 리스트로 만들어주기\n",
    "    valid_file_names = f_folds[f_folds['fold']==idx]['image_id'].unique()\n",
    "    \n",
    "    print(len(train_file_names))\n",
    "    print(len(valid_file_names))\n",
    "    \n",
    "    # 기존 json 형태보고 맞춰서 작성하면 됨\n",
    "    for i,train_file_name in enumerate(train_file_names):\n",
    "        images.append(dict(\n",
    "            license=0,\n",
    "            url=None,\n",
    "            file_name=train_file_name,\n",
    "            height=512,\n",
    "            width=512,\n",
    "            date_captured=None,\n",
    "            id=i)) # 새롭게 이미지 id 번호 지정\n",
    "        \n",
    "        # image_id 를 file_name을 통해서 찾기 image_id=[image_id] 한개의 원소로 이루어짐 [0]으로 부르고 그 중 image id 가져오기\n",
    "        image_id = list(filter(lambda x:x['file_name']==train_file_name,dataset['images']))[0]['id']\n",
    "        # annotations 파일중에 image_id가 image_id랑 같은 것들이 있다면 (한개의 이미지안에 들어있는 한개또는 여러개의 객체리스트)\n",
    "        for x in list(filter(lambda x:x['image_id']==image_id,dataset['annotations'])):\n",
    "            annotations.append(dict(id=len(annotations), # annotations id 를 새로 0번부터 지정\n",
    "                                   image_id=i,\n",
    "                                   category_id=x['category_id'],\n",
    "                                   segmentation=x['segmentation'],\n",
    "                                   area=x['area'],\n",
    "                                   bbox=x['bbox'],\n",
    "                                   iscrows=x['iscrowd']))\n",
    "    \n",
    "    train_ann={}\n",
    "    train_ann['images']=images\n",
    "    train_ann['annotations']=annotations\n",
    "    train_ann['categories']=dataset['categories']\n",
    "    \n",
    "    with open(f'train_data{idx}.json','w') as f:\n",
    "        json.dump(train_ann,f,indent=4)\n",
    "        \n",
    "    images = []\n",
    "    annotations = []\n",
    "    for i, valid_file_name in (enumerate(valid_file_names)):\n",
    "        images.append(dict(\n",
    "                license=0,\n",
    "                url=None,\n",
    "                file_name=valid_file_name,\n",
    "                height=512,\n",
    "                width=512,\n",
    "                date_captured=None,\n",
    "                id=i\n",
    "            ))\n",
    "\n",
    "        image_id = list(filter(lambda x: x['file_name'] == valid_file_name, dataset['images']))[0]['id']\n",
    "        for x in list(filter(lambda x: x['image_id'] == image_id, dataset['annotations'])):\n",
    "            annotations.append(dict(id=len(annotations), \n",
    "                                image_id=i, \n",
    "                                category_id=x['category_id'], \n",
    "                                segmentation=x['segmentation'],\n",
    "                                area=x['area'], \n",
    "                                bbox=x['bbox'], \n",
    "                                iscrowd=x['iscrowd']))\n",
    "    \n",
    "    valid_ann = {}\n",
    "    valid_ann['images'] =  images\n",
    "    valid_ann['annotations'] = annotations\n",
    "    valid_ann['categories'] = dataset['categories']\n",
    "        \n",
    "    with open(f'valid_data{idx}.json', 'w') as f:\n",
    "        json.dump(valid_ann, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
