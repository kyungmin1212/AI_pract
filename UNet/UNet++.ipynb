{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet++.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1Q7CNHV2KwF4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class conv_block_nested(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(conv_block_nested, self).__init__()\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
        "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        output = self.activation(x)\n",
        "        return output\n",
        "\n",
        "class UNetPlusPlus(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, out_ch=1, n1=64, height=512, width=512, supervision=True):\n",
        "        super(UNetPlusPlus, self).__init__()\n",
        "\n",
        "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16] # 64,128,256,512,1024 채널수\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 512,256,128,64 로 이미지 사이즈를 키워줌 \n",
        "        self.Up = nn.ModuleList([nn.Upsample(size=(height//(2**c), width//(2**c)), mode='bilinear', align_corners=True) for c in range(4)]) # nn.Upsample = nn.functional.interpolate\n",
        "        self.supervision = supervision\n",
        "\n",
        "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0]) #  (0,0) , 3-> 64\n",
        "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1]) # (1,0) , 64-> 128\n",
        "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2]) # (2,0) , 128-> 256\n",
        "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3]) # (3,0) , 256-> 512\n",
        "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4]) # (4,0) , 512-> 1024\n",
        "\n",
        "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0]) # (0,1) 64+128-> 64\n",
        "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1]) # (1,1) 128+256-> 128\n",
        "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2]) # (2,1) 256+512-> 256\n",
        "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3]) # (3,1) 512+1024-> 512\n",
        "\n",
        "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0]) # (0,2) 64+64+128-> 64\n",
        "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1]) # (1,2) 128+128+256-> 128\n",
        "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2]) # (2,2) 256+256+512-> 256\n",
        "\n",
        "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0]) # (0,3) 64+64+64+128-> 64\n",
        "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1]) # (1,3) 128+128+128+256-> 128\n",
        "\n",
        "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0]) # (0,4) 64+64+64+64+128-> 64\n",
        "\n",
        "        self.seg_outputs = nn.ModuleList([nn.Conv2d(filters[0], out_ch, kernel_size=1, padding=0) for _ in range(4)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # concat 할때는 항상 이미지 사이즈 맞춰주기 self.Up\n",
        "        \n",
        "        seg_outputs = []\n",
        "        x0_0 = self.conv0_0(x) # channel = 64\n",
        "        x1_0 = self.conv1_0(self.pool(x0_0)) # channel = 128\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up[0](x1_0)], 1)) # channel = 64 , x1_0의 이미지사이즈는 절반으로 변했으므로 512x512로 다시 up해줌(Up[0])\n",
        "        seg_outputs.append(self.seg_outputs[0](x0_1)) # x0_1에 1x1 Conv 적용해서 num_classes만큼 변경\n",
        "\n",
        "        x2_0 = self.conv2_0(self.pool(x1_0)) # 256\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up[1](x2_0)], 1)) # 128 \n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up[0](x1_1)], 1)) # 64 ,\n",
        "        seg_outputs.append(self.seg_outputs[1](x0_2)) #x0_2에 1x1 Conv 적용해서 num_classes만큼 변경\n",
        "\n",
        "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up[2](x3_0)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up[1](x2_1)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up[0](x1_2)], 1))\n",
        "        seg_outputs.append(self.seg_outputs[2](x0_3)) #x0_3에 1x1 Conv 적용해서 num_classes만큼 변경\n",
        "\n",
        "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
        "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up[3](x4_0)], 1))\n",
        "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up[2](x3_1)], 1))\n",
        "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up[1](x2_2)], 1))\n",
        "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up[0](x1_3)], 1))\n",
        "        seg_outputs.append(self.seg_outputs[3](x0_4)) #x0_4에 1x1 Conv 적용해서 num_classes만큼 변경\n",
        "\n",
        "        if self.supervision: \n",
        "            return torch.stack(seg_outputs)\n",
        "        else:\n",
        "            return seg_outputs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
        "\n",
        "model = UNetPlusPlus(out_ch=12, supervision=True)\n",
        "x = torch.randn([1, 3, 512, 512])\n",
        "print(\"input shape : \", x.shape)\n",
        "out = model(x).to(device)\n",
        "print(\"output shape : \", out.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNIu_z0dc1HW",
        "outputId": "7f4a1b0b-3c83-41c0-fcf5-875c0cc6b457"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape :  torch.Size([1, 3, 512, 512])\n",
            "output shape :  torch.Size([4, 1, 12, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CrD3K9KmjQh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}